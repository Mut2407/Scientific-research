import cv2
import numpy as np
import time
import pyttsx3
from keras.models import load_model
from collections import deque, Counter
from play_emotion import play_playlist

# --- Cáº¥u hÃ¬nh giá»ng nÃ³i ---
engine = pyttsx3.init()
engine.setProperty('rate', 160)
engine.setProperty('volume', 0.9)

# --- Náº¡p model ---
model = load_model('model_file_30epochs.h5')
faceDetect = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')

# --- NhÃ£n cáº£m xÃºc ---
labels_dict = {
    0: 'angry', 1: 'disgust', 2: 'fear',
    3: 'happy', 4: 'neutral', 5: 'sad', 6: 'surprise'
}

labels_vn = {
    'angry': 'Tá»©c giáº­n', 'disgust': 'GhÃª sá»£', 'fear': 'Sá»£ hÃ£i',
    'happy': 'Vui váº»', 'neutral': 'BÃ¬nh thÆ°á»ng', 'sad': 'Buá»“n bÃ£', 'surprise': 'Ngáº¡c nhiÃªn'
}

# --- GÃ¡n giÃ¡ trá»‹ Valenceâ€“Arousal ---
emotion_va = {
    'angry': (-0.6, 0.8),
    'disgust': (-0.7, 0.6),
    'fear': (-0.8, 0.9),
    'happy': (0.8, 0.8),
    'neutral': (0.0, 0.3),
    'sad': (-0.7, 0.2),
    'surprise': (0.5, 0.9)
}

# --- Khá»Ÿi táº¡o biáº¿n ---
video = cv2.VideoCapture(0)
emotion_history = deque(maxlen=30)  # lÆ°u cáº£m xÃºc trong 30 khung hÃ¬nh (~10s)
current_emotion = None
last_change_time = time.time()
min_confidence = 0.6  # ngÆ°á»¡ng tin cáº­y tá»‘i thiá»ƒu
stable_seconds = 8    # yÃªu cáº§u cáº£m xÃºc má»›i á»•n Ä‘á»‹nh â‰¥ 8 giÃ¢y trÆ°á»›c khi Ä‘á»•i nháº¡c

print("ğŸ§  Há»‡ thá»‘ng nháº­n diá»‡n cáº£m xÃºc nÃ¢ng cao Ä‘ang khá»Ÿi Ä‘á»™ng... (nháº¥n Q Ä‘á»ƒ thoÃ¡t)")

while True:
    ret, frame = video.read()
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = faceDetect.detectMultiScale(gray, 1.3, 3)

    for x, y, w, h in faces:
        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)

        sub_face_img = gray[y:y+h, x:x+w]
        resized = cv2.resize(sub_face_img, (48, 48))
        normalize = resized / 255.0
        reshaped = np.reshape(normalize, (1, 48, 48, 1))
        result = model.predict(reshaped)

        confidence = np.max(result)
        label = np.argmax(result, axis=1)[0]
        predicted_emotion = labels_dict[label]

        # --- Ãp dá»¥ng ngÆ°á»¡ng tin cáº­y ---
        if confidence >= min_confidence:
            emotion_history.append(predicted_emotion)

        # --- TÃ­nh cáº£m xÃºc á»•n Ä‘á»‹nh ---
        if len(emotion_history) >= 10:
            dominant_emotion = Counter(emotion_history).most_common(1)[0][0]
        else:
            dominant_emotion = predicted_emotion

        # --- TÃ­nh trung bÃ¬nh má»©c cáº£m xÃºc (Valence, Arousal) ---
        valence_vals = [emotion_va[e][0] for e in emotion_history if e in emotion_va]
        arousal_vals = [emotion_va[e][1] for e in emotion_history if e in emotion_va]
        avg_valence = np.mean(valence_vals) if valence_vals else 0
        avg_arousal = np.mean(arousal_vals) if arousal_vals else 0

        # --- Hiá»ƒn thá»‹ lÃªn khung hÃ¬nh ---
        cv2.putText(frame, f"{dominant_emotion} ({confidence:.2f})", (x, y-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(frame, f"V:{avg_valence:.2f} A:{avg_arousal:.2f}", (x, y+h+25),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

        # --- Quy táº¯c Ä‘á»•i nháº¡c: chá»‰ khi cáº£m xÃºc khÃ¡c vÃ  á»•n Ä‘á»‹nh lÃ¢u ---
        current_time = time.time()
        if dominant_emotion != current_emotion:
            if current_time - last_change_time >= stable_seconds:
                current_emotion = dominant_emotion
                vn_name = labels_vn[current_emotion]
                print(f"ğŸ§© Cáº£m xÃºc á»•n Ä‘á»‹nh: {vn_name} (V={avg_valence:.2f}, A={avg_arousal:.2f})")
                engine.say(f"TÃ´i cáº£m nháº­n báº¡n Ä‘ang {vn_name}")
                engine.runAndWait()

                if current_emotion in ["happy", "sad", "angry", "neutral"]:
                    play_playlist(current_emotion)
                    print(f"ğŸµ Äang phÃ¡t nháº¡c phÃ¹ há»£p vá»›i cáº£m xÃºc: {vn_name}")

                last_change_time = current_time
        else:
            # reset thá»i gian náº¿u váº«n cÃ¹ng cáº£m xÃºc
            last_change_time = current_time

    cv2.imshow("Emotion Detection - Smoothed", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

video.release()
cv2.destroyAllWindows()
